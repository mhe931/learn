
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Governance - ADA Study Guide</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="container">
        <header class="header">
            <h1>AI Governance</h1>
            <button class="menu-toggle" id="menu-toggle">&#9776;</button>
        </header>

        <div class="sidebar" id="sidebar">
            <nav>
                <ul>
                    <li><a href="index.html">Dashboard</a></li>
                    <li><a href="foundations.html">Foundational Principles</a></li>
                    <li><a href="modeling.html">Data Modeling & Warehousing</a></li>
                    <li><a href="mesh-fabric.html">Data Mesh vs. Fabric</a></li>
                    <li><a href="ai-architecture.html">AI in Data Architecture</a></li>
                    <li><a href="governance.html" class="active">AI Governance</a></li>
                </ul>
            </nav>
        </div>

        <main class="main-content">
            <h2>The Imperative of AI Governance</h2>
            <p>As AI systems become more powerful and integrated into business processes, robust governance is no longer optional. AI Governance is the framework of rules, practices, and tools to ensure AI is developed and used responsibly, ethically, and in compliance with regulations.</p>

            <h3>Key Regulatory Frameworks</h3>
            
            <h4>The EU AI Act</h4>
            <ul>
                <li><strong>Approach:</strong> Risk-based. AI systems are categorized into four levels: Unacceptable Risk (banned), High Risk, Limited Risk, and Minimal Risk.</li>
                <li><strong>High-Risk Systems:</strong> Subject to strict requirements, including data quality, transparency, human oversight, and robustness. Examples include AI in critical infrastructure, medical devices, and law enforcement.</li>
                <li><strong>Key Mandate:</strong> Requires conformity assessments before high-risk AI systems can be placed on the market.</li>
            </ul>

            <h4>NIST AI Risk Management Framework (RMF)</h4>
            <ul>
                <li><strong>Approach:</strong> A voluntary framework designed to help organizations manage AI risks. It is not a regulation but a best-practice guide.</li>
                <li><strong>Core Functions:</strong>
                    <ul>
                        <li><strong>Govern:</strong> Establish a culture of risk management.</li>
                        <li><strong>Map:</strong> Identify the context and risks of the AI system.</li>
                        <li><strong>Measure:</strong> Analyze and track the identified risks.</li>
                        <li><strong>Manage:</strong> Treat the risks with appropriate mitigation strategies.</li>
                    </ul>
                </li>
                 <li><strong>Focus:</strong> Aims to improve trustworthiness of AI by promoting valid, reliable, safe, secure, and fair systems.</li>
            </ul>
            
            <hr>

            <h2>Practical AI Risk Management</h2>
            
            <h3><span class="midterm-topic">The AI Risk Atlas</span></h3>
            <p>The concept of an "AI Risk Atlas" is a strategic tool for organizations to systematically map and categorize potential AI-related risks. It's a living document that serves as a central registry for AI vulnerabilities.</p>
            <ul>
                <li><strong>Purpose:</strong> To move from abstract principles to concrete risk management. It helps answer: What could go wrong? What is the likelihood? What is the impact?</li>
                <li><strong>Content:</strong> Typically includes risk domains such as:
                    <ul>
                        <li><strong>Data-related Risks:</strong> Poisoning, bias, privacy breaches.</li>
                        <li><strong>Model-related Risks:</strong> Hallucinations, brittleness, explainability issues.</li>
                        <li><strong>System-level Risks:</strong> Over-reliance, security vulnerabilities, prompt injection.</li>
                        <li><strong>Ethical & Societal Risks:</strong> Unfairness, job displacement, malicious use.</li>
                    </ul>
                </li>
            </ul>
            
            <h3>OWASP Top 10 for LLMs</h3>
            <p>The Open Web Application Security Project (OWASP) has extended its focus to Large Language Models, identifying the most critical security vulnerabilities.</p>
            <pre><code>
1. Prompt Injection
2. Insecure Output Handling
3. Training Data Poisoning
4. Model Denial of Service
5. Supply Chain Vulnerabilities
6. Sensitive Information Disclosure
7. Insecure Plugin Design
8. Excessive Agency
9. Overreliance
10. Model Theft
            </code></pre>

            <hr>

            <h2>Certification and Standardization</h2>
            <h3><span class="midterm-topic">AI Certification & ISO/IEC 42001</span></h3>
            <p>To build trust and ensure compliance, the industry is moving towards formal certification of AI systems and management processes.</p>
            <ul>
                <li><strong>ISO/IEC 42001:</strong> This is the first international standard for an AI Management System (AIMS).</li>
                <li><strong>Analogy:</strong> Think of it as the "ISO 9001 for Quality" or "ISO 27001 for Information Security," but applied to the unique challenges of AI.</li>
                <li><strong>Goal:</strong> It provides a structured framework for organizations to plan, implement, maintain, and continually improve their AI governance. Achieving certification demonstrates a commitment to responsible AI.</li>
            </ul>
            
            <div class="review-section">
                <h3>Review & Exam Prep</h3>
                <ul>
                    <li><strong>EU AI Act vs. NIST RMF:</strong> Know the difference. The EU Act is a binding regulation with a risk-based pyramid. The NIST RMF is a voluntary framework for *how* to manage risk.</li>
                    <li>The <span class="midterm-topic">AI Risk Atlas</span> is a practical tool for mapping specific, concrete risks beyond general principles. Be prepared to list a few risk categories (e.g., data, model, system).</li>
                    <li><span class="midterm-topic">ISO 42001</span> is the key standard for an AI Management System. It's about formalizing the process of governing AI within an organization.</li>
                    <li>Be familiar with the top OWASP LLM risks, especially **Prompt Injection** and **Training Data Poisoning**.</li>
                </ul>
            </div>

        </main>
    </div>

    <script>
        const menuToggle = document.getElementById('menu-toggle');
        const sidebar = document.getElementById('sidebar');

        menuToggle.addEventListener('click', () => {
            sidebar.classList.toggle('active');
        });

        document.addEventListener('click', function(event) {
            const isClickInsideSidebar = sidebar.contains(event.target);
            const isClickOnMenuToggle = menuToggle.contains(event.target);

            if (!isClickInsideSidebar && !isClickOnMenuToggle && sidebar.classList.contains('active')) {
                sidebar.classList.remove('active');
            }
        });
    </script>
</body>
</html>
